{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘tract_merged.csv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Griffin Davis, The University of Texas at Dallas\n",
    "# (C) 2022\n",
    "# Data source:\n",
    "# Chetty, Raj; Friedman, John; Hendren, Nathaniel; Jones, Maggie R.; Porter, Sonya R., 2022, \n",
    "# \"Replication Data for: The Opportunity Atlas: Mapping the Childhood Roots of Social Mobility\", \n",
    "# https://doi.org/10.7910/DVN/NKCQM1, Harvard Dataverse, V1, UNF:6:wwWmCZy1LUqtq02qHdCKFQ== [fileUNF] \n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from urllib.parse import urlparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "nnF = nn.functional\n",
    "\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "reload(logging) # Notebook workaround\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(threadName)s] [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/mdn.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Download data\n",
    "!wget -nc https://personal.utdallas.edu/~gcd/data/tract_merged.csv\n",
    "ds = pd.read_csv('tract_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of columns\n",
    "cols = ['id', 'hhinc_mean2000', 'mean_commutetime2000', 'frac_coll_plus2000', 'frac_coll_plus2010', \n",
    "        'med_hhinc1990', 'med_hhinc2016', 'popdensity2000', 'poor_share2010', 'poor_share2000', \n",
    "        'poor_share1990', 'gsmn_math_g3_2013', 'traveltime15_2010', 'emp2000', 'singleparent_share1990',\n",
    "        'singleparent_share2010', 'singleparent_share2000', \n",
    "        'mail_return_rate2010', 'jobs_total_5mi_2015', 'jobs_highpay_5mi_2015', \n",
    "        'popdensity2010', 'job_density_2013', 'kfr_pooled_pooled_p1', \n",
    "        'kfr_pooled_pooled_p25', 'kfr_pooled_pooled_p50', 'kfr_pooled_pooled_p75', 'kfr_pooled_pooled_p100']\n",
    "\n",
    "excluded = ['rent_twobed2015', 'ln_wage_growth_hs_grad', 'ann_avg_job_growth_2004_2013']\n",
    "\n",
    "full_cols = cols + excluded\n",
    "\n",
    "# Handle null data\n",
    "ds_full = ds[ds.columns[ds.columns.isin(full_cols)]]\n",
    "ds = ds[ds.columns[ds.columns.isin(cols)]]\n",
    "ds = ds.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN (Missing Values Removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle split the data into training and test sets (75% / 25%)\n",
    "train, test = train_test_split(ds)\n",
    "\n",
    "train_X = train.loc[:,'hhinc_mean2000':'job_density_2013']\n",
    "test_X = test.loc[:,'hhinc_mean2000':'job_density_2013']\n",
    "\n",
    "percentiles = ['kfr_pooled_pooled_p1', 'kfr_pooled_pooled_p25', 'kfr_pooled_pooled_p50', 'kfr_pooled_pooled_p75']\n",
    "train_Y = train.loc[:, percentiles[0]]\n",
    "test_Y = test.loc[:, percentiles[0]]\n",
    "\n",
    "# Reset indexes and convert Y to pd.Series\n",
    "train_X.reset_index(drop=True, inplace=True)\n",
    "train_Y = train_Y.reset_index(drop=True).squeeze()\n",
    "test_X.reset_index(drop=True, inplace=True)\n",
    "test_Y = test_Y.reset_index(drop=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Mixture Density Network, without handling for missing input features\n",
    "features = train_X.shape[1]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, features, hidden_dim, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(features, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        params = self.seq(x)\n",
    "        mu, sigma = torch.tensor_split(params, params.shape[0], dim=0)\n",
    "        \n",
    "        return mu, sigma+1\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        mu, sigma = self.forward(x)\n",
    "        dist = Normal(mu, sigma)\n",
    "        return -dist.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mdn(mdn, X, Y, optimizer, verbose):\n",
    "    mdn.train()\n",
    "    \n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    Y.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    for index, row in X.iterrows():\n",
    "        x = torch.tensor(np.double(row.values))\n",
    "        y = torch.tensor(np.double(Y.iloc[index]))\n",
    "        \n",
    "        loss = mdn.loss(x, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if verbose and index % 10000 == 0:\n",
    "            logging.info.info(f\"index: {index} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mdn(mdn, X, Y, verbose):\n",
    "    mdn.eval()\n",
    "\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    Y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    test_loss = 0\n",
    "    sq_er = []\n",
    "    with torch.no_grad():\n",
    "        for index, row in X.iterrows():\n",
    "            x = torch.tensor(np.double(row.values))\n",
    "            y = torch.tensor(np.double(Y.iloc[index]))\n",
    "            loss = mdn.loss(x, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            mu, sigma = mdn.forward(x)\n",
    "\n",
    "            sq_er.append((mu.item() - y)**2)\n",
    "\n",
    "    test_loss /= test_X.shape[0]\n",
    "    \n",
    "    if verbose:\n",
    "        logging.info(f\"Avg test loss: {test_loss}\")\n",
    "        logging.info(f\"Mean squared error: {np.mean(sq_er)}\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cab59566b02416d9e41d6366394ee0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension = 3, Loss = 0.2768381263867698\n",
      "Dimension = 4, Loss = 0.2789649501573936\n",
      "Dimension = 5, Loss = 0.29557487171902286\n",
      "Dimension = 6, Loss = 0.29557487171902286\n",
      "Dimension = 7, Loss = 0.27678297429819837\n",
      "Dimension = 8, Loss = 0.27677964461746984\n",
      "Dimension = 9, Loss = 0.2955755801044583\n",
      "Dimension = 10, Loss = 0.2767739615945039\n",
      "Dimension = 11, Loss = 0.2767723332257522\n",
      "Dimension = 12, Loss = 0.27678039662463905\n",
      "Dimension = 13, Loss = 0.27676444063356503\n",
      "Dimension = 14, Loss = 0.29557487171902286\n",
      "Dimension = 15, Loss = 0.2767818423319893\n",
      "Dimension = 16, Loss = 0.27676558481836744\n",
      "Dimension = 17, Loss = 0.2767831932562505\n",
      "Dimension = 18, Loss = 0.2767636130155072\n",
      "Dimension = 19, Loss = 0.2767720795720673\n",
      "Dimension = 20, Loss = 0.29557487171902286\n",
      "Dimension = 21, Loss = 0.27677251045612\n",
      "Dimension = 22, Loss = 0.2767821537030486\n",
      "Dimension = 23, Loss = 0.29557487171902286\n",
      "Dimension = 24, Loss = 0.29557487171902286\n",
      "Dimension = 25, Loss = 0.27674490638982185\n",
      "Dimension = 26, Loss = 0.27677647070538497\n",
      "Dimension = 27, Loss = 0.2767582652135724\n",
      "Dimension = 28, Loss = 0.2767785725211536\n",
      "Dimension = 29, Loss = 0.2767700134633984\n",
      "Selected number of sigmoid activations: 25\n"
     ]
    }
   ],
   "source": [
    "# Determine number of Sigmoid activations to use in hidden layer\n",
    "# 10-fold hyperparameter cross validation using training data\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "losses = {}\n",
    "\n",
    "# Setup folder to save hypervalidation models\n",
    "hyperPath = 'hypervalidation'\n",
    "if not os.path.exists(hyperPath):\n",
    "    os.makedirs(hyperPath)\n",
    "\n",
    "# Try each option for number of Sigmoid activations\n",
    "for hidden_dim in tqdm(range(3, 30)):\n",
    "    # Create network with that hyperparameter\n",
    "    mdn = Net(features, hidden_dim, 2).double()\n",
    "    optimizer = torch.optim.Adam(mdn.parameters(), lr=0.0001)\n",
    "\n",
    "    # Do 10-fold cross validation and store results of tests in array\n",
    "    dim_loss = []\n",
    "    for train_index, test_index in kf.split(train_X):\n",
    "        X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "        Y_train, Y_test = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "\n",
    "        train_mdn(mdn, X_train, Y_train, optimizer, False)\n",
    "        dim_loss.append(test_mdn(mdn, X_test, Y_test, False))\n",
    "    \n",
    "    # Store average test results for this hyperparameter option\n",
    "    losses[hidden_dim] = np.mean(dim_loss)\n",
    "\n",
    "    # Save the hypervalidation model\n",
    "    torch.save(mdn, f'{hyperPath}/{hidden_dim}_activ_mdn.pt')\n",
    "\n",
    "    logging.info(\"Dimension = \" + str(hidden_dim) + \", Loss = \" + str(losses[hidden_dim]))\n",
    "\n",
    "# Select best hyperparameter\n",
    "min_loss = np.inf\n",
    "min_dim = 0\n",
    "for hidden_dim in losses:\n",
    "    if losses[hidden_dim] < min_loss:\n",
    "        min_loss = losses[hidden_dim]\n",
    "        min_dim = hidden_dim\n",
    "\n",
    "logging.info(\"Selected number of sigmoid activations: \" + str(min_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 loss: tensor([1.2939], dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "index: 10000 loss: tensor([0.9458], dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "index: 20000 loss: tensor([0.9245], dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "index: 30000 loss: tensor([0.9222], dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "index: 40000 loss: tensor([0.9221], dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "index: 50000 loss: tensor([0.9198], dtype=torch.float64, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Retrain with full training dataset (selected 25)\n",
    "mdn = Net(features, min_dim, 2).double()\n",
    "optimizer = torch.optim.Adam(mdn.parameters(), lr=0.0001)\n",
    "\n",
    "train_mdn(mdn, train_X, train_Y, optimizer, True)\n",
    "\n",
    "# Save the final model\n",
    "torch.save(mdn, f'simple_mdn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg test loss: 0.9225062879034627\n",
      "Mean squared error: 0.007135509397580172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9225062879034627"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with reserved data\n",
    "test_mdn(mdn, test_X, test_Y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN with Expectation Maximization to Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for full dataset (including missing data)\n",
    "\n",
    "# Shuffle split the data into training and test sets (75% / 25%)\n",
    "train, test = train_test_split(ds_full)\n",
    "\n",
    "train_X = train.loc[:,'hhinc_mean2000':'job_density_2013']\n",
    "test_X = test.loc[:,'hhinc_mean2000':'job_density_2013']\n",
    "\n",
    "percentiles = ['kfr_pooled_pooled_p1', 'kfr_pooled_pooled_p25', 'kfr_pooled_pooled_p50', 'kfr_pooled_pooled_p75']\n",
    "train_Y = train.loc[:, percentiles[0]]\n",
    "test_Y = test.loc[:, percentiles[0]]\n",
    "\n",
    "# Reset indexes and convert Y to pd.Series\n",
    "train_X.reset_index(drop=True, inplace=True)\n",
    "train_Y = train_Y.reset_index(drop=True).squeeze()\n",
    "test_X.reset_index(drop=True, inplace=True)\n",
    "test_Y = test_Y.reset_index(drop=True).squeeze()\n",
    "\n",
    "features = train_X.shape[1]\n",
    "data_points = train_X.shape[0]\n",
    "\n",
    "# Get missing indexes\n",
    "train_Xmissing = np.isnan(train_X)\n",
    "train_imissing = []\n",
    "for m in range(data_points):\n",
    "    row = []\n",
    "    for i in range(features):\n",
    "        if train_Xmissing.iloc[m][i]:\n",
    "            row.append(i)\n",
    "    train_imissing.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixture Density Network with expectation maximization algorithm to handle missing data\n",
    "\n",
    "# Store feature distribution parameters\n",
    "feat_params = []\n",
    "\n",
    "LOSS_SAMPLE_SIZE = 25\n",
    "loss_generator = np.random.default_rng()\n",
    "\n",
    "def init_feat_params(X):\n",
    "    # Initialize feature parameters\n",
    "    for n in range(features):\n",
    "        mu = np.nanmean(X.iloc[:, n])\n",
    "        sigma = np.nanstd(X.iloc[:, n])\n",
    "        feat_params.append((mu, sigma))\n",
    "\n",
    "def p_x(i, xi):\n",
    "    mu, sigma = feat_params[i]\n",
    "    dist = Normal(mu, sigma)\n",
    "    p_xi  = torch.exp(dist.log_prob(torch.tensor(np.double(xi)))).item()\n",
    "    return p_xi\n",
    "\n",
    "class EMNet(nn.Module):\n",
    "    def __init__(self, features, hidden_dim, out_dim):\n",
    "        super(EMNet, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(features, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        params = self.seq(x)\n",
    "        mu, sigma = torch.tensor_split(params, params.shape[0], dim=0)\n",
    "        \n",
    "        return mu, sigma+1\n",
    "\n",
    "    # Evaluate q density for EM algorithm\n",
    "    # For a given data point (x, y)\n",
    "    def q(self, x, y, xmis, imis, mu, sigma):\n",
    "        # p(y | x) with current mu, sigma\n",
    "        y_dist = Normal(mu, sigma)\n",
    "\n",
    "        # =======================\n",
    "        # Numerator of q function\n",
    "        # =======================\n",
    "\n",
    "        # p(y | x)\n",
    "        num = torch.exp(y_dist.log_prob(torch.tensor(np.double(y))))[0].item()\n",
    "\n",
    "        # Product[ p(x_mis) ]\n",
    "        st = time.time()\n",
    "        for k in range(len(xmis)):\n",
    "            num *= p_x(imis[k], xmis[k])\n",
    "\n",
    "        # =========================\n",
    "        # Denominator of q function\n",
    "        # =========================\n",
    "\n",
    "        # Function for the integral\n",
    "        def int_func(*xmis_hat):\n",
    "            # Get product of all p(xmis)\n",
    "            prod = 1\n",
    "            for i in range(len(xmis_hat)):\n",
    "                prod *= p_x(imis[i], xmis_hat[i])\n",
    "            x_hat = x\n",
    "            f_i = 0\n",
    "            # Replace missing values with current guesses\n",
    "            for f in range(len(x_hat)):\n",
    "                if np.isnan(x_hat[f]):\n",
    "                    x_hat[f] = xmis_hat[f_i]\n",
    "                    f_i+=1\n",
    "            # Run X with current guesses through NN\n",
    "            mu_hat, sigma_hat = self.forward(torch.tensor(np.double(x_hat)))\n",
    "            dist = Normal(mu_hat, sigma_hat)\n",
    "            # Return p(y|x)\n",
    "            return torch.exp(dist.log_prob(torch.tensor(np.double(y))))[0].item()\n",
    "\n",
    "        # Setup list of ranges corresponding to num of missing values\n",
    "        ranges = [(-np.inf, np.inf) for i in range(len(imis))]\n",
    "\n",
    "        # Integrate over each xmis, -inf to inf\n",
    "        # st = time.time()\n",
    "        den, err = integrate.nquad(int_func, ranges, opts={'epsabs': np.inf, 'epsrel': np.inf, 'limit': 10})\n",
    "        # print(f\"integral: {round(time.time()-st,1)}s\")\n",
    "\n",
    "        return num/den\n",
    "\n",
    "    # Produce gradients of feature distribution parameters\n",
    "    def grad_mu_xi(self, X, Y, mu_xi, sigma_xi, xi, imis):\n",
    "        m = 0\n",
    "        def int_func(*xmis_hat):\n",
    "            nn_mu, nn_sigma = self.forward(torch.tensor(np.double(X[m])))\n",
    "            \n",
    "            qm = self.q(X[m], Y[m], xmis_hat, imis[m], nn_mu, nn_sigma)\n",
    "            return qm * ((xi[m] / (sigma_xi**2)) - (mu_xi / (sigma_xi**2)))\n",
    "\n",
    "        sum_ints = 0\n",
    "\n",
    "        for m in range(len(X)):\n",
    "            # Setup list of ranges corresponding to num of missing values\n",
    "            ranges = [(-np.inf, np.inf) for i in range(len(imis[m]))]\n",
    "\n",
    "            res, err = integrate.nquad(int_func, ranges, opts={'epsabs': np.inf, 'epsrel': np.inf, 'limit': 20})\n",
    "            sum_ints += res\n",
    "\n",
    "        return sum_ints\n",
    "\n",
    "    def grad_sigma_xi(self, X, Y, mu_xi, sigma_xi, xi, imis):\n",
    "        m = 0\n",
    "        def int_func(*xmis_hat):\n",
    "            nn_mu, nn_sigma = self.forward(torch.tensor(np.double(X[m])))\n",
    "\n",
    "            qm = self.q(X[m], Y[m], xmis_hat, imis[m], nn_mu, nn_sigma)\n",
    "            return qm * ((-1 / sigma_xi) - ((xi[m] - mu_xi) / (sigma_xi**3)))\n",
    "\n",
    "        sum_ints = 0\n",
    "\n",
    "        for m in range(len(X)):\n",
    "            # Setup list of ranges corresponding to num of missing values\n",
    "            ranges = [(-np.inf, np.inf) for i in range(len(imis[m]))]\n",
    "\n",
    "            res, err = integrate.nquad(int_func, ranges, opts={'epsabs': np.inf, 'epsrel': np.inf, 'limit': 25})\n",
    "            sum_ints += res\n",
    "\n",
    "        return sum_ints\n",
    "    \n",
    "    def loss(self, X, Y, imis):\n",
    "        logging.info(\"Calculating loss...\")\n",
    "        m = 0\n",
    "        def int_func(*xmis_hat):\n",
    "            # Replace NaNs with xmis_hat\n",
    "            f_i = 0\n",
    "            # Replace missing values with current guesses\n",
    "            for f in range(len(X[m])):\n",
    "                if np.isnan(X[m, f]):\n",
    "                    X[m, f] = xmis_hat[f_i]\n",
    "                    f_i+=1\n",
    "            # Run X with current guesses through NN\n",
    "            mu, sigma = self.forward(torch.tensor(np.double(X[m])))\n",
    "            dist = Normal(mu, sigma)\n",
    "            # Get p(y|x)\n",
    "            log_p_y_x = dist.log_prob(torch.tensor(np.double(Y[m])))[0].item()\n",
    "\n",
    "            # Get q_m(xmis_hat)\n",
    "            qm = self.q(X[m], Y[m], xmis_hat, imis[m], mu, sigma)\n",
    "            return qm * log_p_y_x\n",
    "\n",
    "        sum_ints = 0\n",
    "\n",
    "        # Randomly sample rows from the training data for each iteration\n",
    "        X_sample = loss_generator.integers(0, high=X.shape[0], size=LOSS_SAMPLE_SIZE)\n",
    "\n",
    "        for m in X_sample:\n",
    "            # Handle case of no missing values\n",
    "            if len(imis[m]) == 0:\n",
    "                logging.info(f\"row {m} : no missing values\")\n",
    "                mu, sigma = self.forward(torch.tensor(np.double(X[m])))\n",
    "                dist = Normal(mu, sigma)\n",
    "                # Get p(y|x)\n",
    "                log_p_y_x = dist.log_prob(torch.tensor(np.double(Y[m])))[0].item()\n",
    "\n",
    "                sum_ints += log_p_y_x\n",
    "            else:\n",
    "                # Setup list of ranges corresponding to num of missing values\n",
    "                ranges = [(-np.inf, np.inf) for i in range(len(imis[m]))]\n",
    "                start_time = time.time()\n",
    "                res, err = integrate.nquad(int_func, ranges, opts={'epsabs': np.inf, 'epsrel': np.inf, 'limit': 20})\n",
    "                logging.info(f\"row {m} : completed {len(imis[m])} dim integral in {int(round(time.time()-start_time, 0))}s\")\n",
    "                sum_ints += res\n",
    "\n",
    "        return -sum_ints\n",
    "\n",
    "    def predict(self, x, imis):\n",
    "        # def int_func(xmis_hat):\n",
    "        #     # Replace NaNs with xmis_hat\n",
    "        #     f_i = 0\n",
    "        #     # Replace missing values with current guesses\n",
    "        #     for f in range(len(x)):\n",
    "        #         if np.isnan(x[f]):\n",
    "        #             x[f] = xmis_hat[f_i]\n",
    "        #             f_i+=1\n",
    "        #     # Run X with current guesses through NN\n",
    "        #     mu, sigma = self.forward(torch.tensor(np.double(x)))\n",
    "        #     dist = Normal(mu, sigma)\n",
    "\n",
    "        #     return qm\n",
    "\n",
    "        # # Setup list of ranges corresponding to num of missing values\n",
    "        # ranges = [(-np.inf, np.inf) for i in range(len(imis))]\n",
    "        # integrate.nquad(int_func, ranges)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training constants\n",
    "TRAIN_ITERATIONS = 100\n",
    "FEAT_PARAM_STEP = 0.001\n",
    "\n",
    "# Train neural network\n",
    "def train_mdn(mdn, X, Y, optimizer, verbose):\n",
    "    mdn.train()\n",
    "\n",
    "    init_feat_params(X)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    Y = Y.to_numpy()\n",
    "    \n",
    "    for index in range(TRAIN_ITERATIONS):\n",
    "        start_time = time.time()\n",
    "        # Calculate NN loss        \n",
    "        loss = mdn.loss(X, Y, train_imissing)\n",
    "        \n",
    "        # Backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update feature parameters using gradient descent\n",
    "        for f in range(features):\n",
    "            cur_mu, cur_sigma = feat_params[f]\n",
    "            xi = X[:,f]\n",
    "            grad_mu = mdn.grad_mu_xi(X, Y, cur_mu, cur_sigma, xi, train_imissing)\n",
    "            grad_sigma = mdn.grad_sigma_xi(X, Y, cur_mu, cur_sigma, xi, train_imissing)\n",
    "\n",
    "            feat_params[f] = (cur_mu+grad_mu, cur_sigma+grad_sigma)\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(f\"iteration: {index} nn loss: {loss} time elapsed: {int(round((time.time()-start_time)/60, 0))}min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network\n",
    "def test_mdn(mdn, X, Y, verbose):\n",
    "    mdn.eval()\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    Y = Y.to_numpy()\n",
    "\n",
    "    # Get missing indexes\n",
    "    Xmissing = np.isnan(X)\n",
    "    imissing = []\n",
    "    for m in range(X.shape[0]):\n",
    "        row = []\n",
    "        for i in range(features):\n",
    "            if Xmissing[m, i]:\n",
    "                row.append(i)\n",
    "        imissing.append(row)\n",
    "    \n",
    "    sq_er = []\n",
    "    with torch.no_grad():\n",
    "        # Get total loss\n",
    "        test_loss = mdn.loss(X, Y, imissing)\n",
    "\n",
    "        # Get squared error for predictions\n",
    "        # for index in range(X.shape[0]):\n",
    "        #     row = X[index, :]\n",
    "        #     x = torch.tensor(np.double(row))\n",
    "        #     y = torch.tensor(np.double(Y[index]))\n",
    "\n",
    "        #     mu, sigma = mdn.forward(x)\n",
    "\n",
    "        #     sq_er.append((mu.item() - y)**2)\n",
    "\n",
    "    test_loss /= test_X.shape[0]\n",
    "    \n",
    "    if verbose:\n",
    "        logging.info(f\"Avg test loss: {test_loss}\")\n",
    "        # print(f\"Mean squared error: {np.mean(sq_er)}\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 11:54:51,996 [MainThread] [INFO] Calculating loss...\n",
      "2022-12-21 11:54:51,997 [MainThread] [INFO] row 12922 : no missing values\n",
      "2022-12-21 11:54:52,001 [MainThread] [INFO] row 21060 : no missing values\n",
      "2022-12-21 11:54:52,004 [MainThread] [INFO] row 1376 : no missing values\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mdn \u001b[39m=\u001b[39m EMNet(features, \u001b[39m10\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mdouble()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(mdn\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_mdn(mdn, train_X, train_Y, optimizer, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Save the final model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m torch\u001b[39m.\u001b[39msave(mdn, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mem_mdn.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36mtrain_mdn\u001b[0;34m(mdn, X, Y, optimizer, verbose)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Calculate NN loss        \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m mdn\u001b[39m.\u001b[39;49mloss(X, Y, train_imissing)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Backpropagate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36mEMNet.loss\u001b[0;34m(self, X, Y, imis)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m ranges \u001b[39m=\u001b[39m [(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(imis[m]))]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m res, err \u001b[39m=\u001b[39m integrate\u001b[39m.\u001b[39;49mnquad(int_func, ranges, opts\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mepsabs\u001b[39;49m\u001b[39m'\u001b[39;49m: np\u001b[39m.\u001b[39;49minf, \u001b[39m'\u001b[39;49m\u001b[39mepsrel\u001b[39;49m\u001b[39m'\u001b[39;49m: np\u001b[39m.\u001b[39;49minf, \u001b[39m'\u001b[39;49m\u001b[39mlimit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m20\u001b[39;49m})\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrow \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m}\u001b[39;00m\u001b[39m : completed \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(imis[m])\u001b[39m}\u001b[39;00m\u001b[39m dim integral in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart_time, \u001b[39m0\u001b[39m))\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m sum_ints \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1097\u001b[0m, in \u001b[0;36mnquad\u001b[0;34m(func, ranges, args, opts, full_output)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1096\u001b[0m     opts \u001b[39m=\u001b[39m [opt \u001b[39mif\u001b[39;00m callable(opt) \u001b[39melse\u001b[39;00m _OptFunc(opt) \u001b[39mfor\u001b[39;00m opt \u001b[39min\u001b[39;00m opts]\n\u001b[0;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m _NQuad(func, ranges, opts, full_output)\u001b[39m.\u001b[39;49mintegrate(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1151\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1151\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39;49margs, full_output\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_output,\n\u001b[1;32m   1152\u001b[0m               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt)\n\u001b[1;32m   1153\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:411\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    408\u001b[0m flip, a, b \u001b[39m=\u001b[39m b \u001b[39m<\u001b[39m a, \u001b[39mmin\u001b[39m(a, b), \u001b[39mmax\u001b[39m(a, b)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[1;32m    412\u001b[0m                    points)\n\u001b[1;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:525\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    524\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39;49m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1151\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1151\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39;49margs, full_output\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_output,\n\u001b[1;32m   1152\u001b[0m               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt)\n\u001b[1;32m   1153\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:411\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    408\u001b[0m flip, a, b \u001b[39m=\u001b[39m b \u001b[39m<\u001b[39m a, \u001b[39mmin\u001b[39m(a, b), \u001b[39mmax\u001b[39m(a, b)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[1;32m    412\u001b[0m                    points)\n\u001b[1;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:525\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    524\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39;49m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36mEMNet.loss.<locals>.int_func\u001b[0;34m(*xmis_hat)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m log_p_y_x \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mlog_prob(torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mdouble(Y[m])))[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m \u001b[39m# Get q_m(xmis_hat)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m qm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq(X[m], Y[m], xmis_hat, imis[m], mu, sigma)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m \u001b[39mreturn\u001b[39;00m qm \u001b[39m*\u001b[39m log_p_y_x\n",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36mEMNet.q\u001b[0;34m(self, x, y, xmis, imis, mu, sigma)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m ranges \u001b[39m=\u001b[39m [(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(imis))]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Integrate over each xmis, -inf to inf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# st = time.time()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m den, err \u001b[39m=\u001b[39m integrate\u001b[39m.\u001b[39;49mnquad(int_func, ranges, opts\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mepsabs\u001b[39;49m\u001b[39m'\u001b[39;49m: np\u001b[39m.\u001b[39;49minf, \u001b[39m'\u001b[39;49m\u001b[39mepsrel\u001b[39;49m\u001b[39m'\u001b[39;49m: np\u001b[39m.\u001b[39;49minf, \u001b[39m'\u001b[39;49m\u001b[39mlimit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m10\u001b[39;49m})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39m# print(f\"integral: {round(time.time()-st,1)}s\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mreturn\u001b[39;00m num\u001b[39m/\u001b[39mden\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1097\u001b[0m, in \u001b[0;36mnquad\u001b[0;34m(func, ranges, args, opts, full_output)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1096\u001b[0m     opts \u001b[39m=\u001b[39m [opt \u001b[39mif\u001b[39;00m callable(opt) \u001b[39melse\u001b[39;00m _OptFunc(opt) \u001b[39mfor\u001b[39;00m opt \u001b[39min\u001b[39;00m opts]\n\u001b[0;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m _NQuad(func, ranges, opts, full_output)\u001b[39m.\u001b[39;49mintegrate(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1151\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1151\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39;49margs, full_output\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_output,\n\u001b[1;32m   1152\u001b[0m               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt)\n\u001b[1;32m   1153\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:411\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    408\u001b[0m flip, a, b \u001b[39m=\u001b[39m b \u001b[39m<\u001b[39m a, \u001b[39mmin\u001b[39m(a, b), \u001b[39mmax\u001b[39m(a, b)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[1;32m    412\u001b[0m                    points)\n\u001b[1;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:525\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    524\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39;49m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1151\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1151\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39;49margs, full_output\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_output,\n\u001b[1;32m   1152\u001b[0m               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt)\n\u001b[1;32m   1153\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:411\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    408\u001b[0m flip, a, b \u001b[39m=\u001b[39m b \u001b[39m<\u001b[39m a, \u001b[39mmin\u001b[39m(a, b), \u001b[39mmax\u001b[39m(a, b)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[1;32m    412\u001b[0m                    points)\n\u001b[1;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mobility-models/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:525\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    524\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39;49m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36mEMNet.q.<locals>.int_func\u001b[0;34m(*xmis_hat)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m prod \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(xmis_hat)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     prod \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m p_x(imis[i], xmis_hat[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m x_hat \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m f_i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32m/Users/gcd/utd/mobility-models/mdn.ipynb Cell 16\u001b[0m in \u001b[0;36mp_x\u001b[0;34m(i, xi)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m mu, sigma \u001b[39m=\u001b[39m feat_params[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m dist \u001b[39m=\u001b[39m Normal(mu, sigma)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m p_xi  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(dist\u001b[39m.\u001b[39mlog_prob(torch\u001b[39m.\u001b[39;49mtensor(np\u001b[39m.\u001b[39;49mdouble(xi))))\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gcd/utd/mobility-models/mdn.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m p_xi\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# Retrain with full training dataset (selected 10)\n",
    "mdn = EMNet(features, 10, 2).double()\n",
    "optimizer = torch.optim.Adam(mdn.parameters(), lr=0.0001)\n",
    "\n",
    "train_mdn(mdn, train_X, train_Y, optimizer, True)\n",
    "\n",
    "# Save the final model\n",
    "torch.save(mdn, f'em_mdn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mobility-models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce1c8699971c3abca39737a4f17ac27a5a89024d987616fa9a36ba7fc3fab9ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
